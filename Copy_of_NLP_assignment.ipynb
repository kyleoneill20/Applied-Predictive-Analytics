{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyleoneill20/Applied-Predictive-Analytics/blob/main/Copy_of_NLP_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_Z-i5i_PcHf"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV9WW7voPcHj"
      },
      "source": [
        "# Natural Language Processing </a>\n",
        "\n",
        "## Assignment: K Nearest Neighbors Model for the IMDB Movie Review Dataset\n",
        "\n",
        "For the final project, build a K Nearest Neighbors model to predict the sentiment (positive or negative) of movie reviews. The dataset is originally hosted here: http://ai.stanford.edu/~amaas/data/sentiment/\n",
        "\n",
        "Use the notebooks from the class and implement the model, train and test with the corresponding datasets.\n",
        "\n",
        "You can follow these steps:\n",
        "1. Read training-test data (Given)\n",
        "2. Train a KNN classifier (Implement)\n",
        "3. Make predictions on your test dataset (Implement)\n",
        "4. Expermintation (Implement)\n",
        "\n",
        "__You can use the KNN Classifier from here: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf9gzc3NPcHm"
      },
      "source": [
        "## 1. Reading the dataset\n",
        "\n",
        "We will use the __pandas__ library to read our dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R1S95FYPcHm"
      },
      "source": [
        "#### __Training data:__\n",
        "Let's read our training data. Here, we have the text and label fields. Labe is 1 for positive reviews and 0 for negative reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imYuQ2EcPcHn",
        "outputId": "3de36e8c-1c0a-49a2-e6cd-9a816dedc74b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  label\n",
            "0  This movie makes me want to throw up every tim...      0\n",
            "1  Listening to the director's commentary confirm...      0\n",
            "2  One of the best Tarzan films is also one of it...      1\n",
            "3  Valentine is now one of my favorite slasher fi...      1\n",
            "4  No mention if Ann Rivers Siddons adapted the m...      0\n",
            "                                                text  label\n",
            "0  What I hoped for (or even expected) was the we...      0\n",
            "1  Garden State must rate amongst the most contri...      0\n",
            "2  There is a lot wrong with this film. I will no...      1\n",
            "3  To qualify my use of \"realistic\" in the summar...      1\n",
            "4  Dirty War is absolutely one of the best politi...      1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Reading training and test data\n",
        "train_df = pd.read_csv('https://raw.githubusercontent.com/aws-samples/aws-machine-learning-university-accelerated-nlp/master/data/final_project/imdb_train.csv')\n",
        "test_df = pd.read_csv('https://raw.githubusercontent.com/aws-samples/aws-machine-learning-university-accelerated-nlp/master/data/final_project/imdb_test.csv')\n",
        "\n",
        "# Displaying the first few rows of the dataset\n",
        "print(train_df.head())\n",
        "print(test_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5c7uQRYPcHn"
      },
      "source": [
        "#### __Test data:__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiBpa04fPcHo"
      },
      "outputs": [],
      "source": [
        "# Separating features and labels\n",
        "X_train = train_df['text']\n",
        "y_train = train_df['label']\n",
        "X_test = test_df['text']\n",
        "y_test = test_df['label']\n",
        "\n",
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # Limit the number of features for efficiency\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Splitting the training data into training and validation sets\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_tfidf, y_train, test_size=0.2, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n7O1xvmPcHp"
      },
      "source": [
        "## 2. Train a KNN Classifier\n",
        "Here, you will apply pre-processing operations we covered in the class. Then, you can split your dataset to training and validation here. For your first submission, you will use __K Nearest Neighbors Classifier__. It is available [here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5f90bOZGPcHp",
        "outputId": "873e608b-1fb1-4a57-80a1-6dfd97f9b709",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 72.90%\n"
          ]
        }
      ],
      "source": [
        "# Implement this\n",
        "\n",
        "# Initializing the KNN Classifier with k=5 (default)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Training the classifier\n",
        "knn.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Making predictions on the validation set\n",
        "y_val_pred = knn.predict(X_val_split)\n",
        "\n",
        "# Evaluating performance on validation set\n",
        "val_accuracy = accuracy_score(y_val_split, y_val_pred)\n",
        "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rieXB-QtPcHq"
      },
      "source": [
        "## 3. Make predictions on your test dataset\n",
        "\n",
        "Once we select our best performing model, we can use it to make predictions on the test dataset. You can simply use __.fit()__ function with your training data to use the best performing K value and use __.predict()__ with your test data to get your test predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BssNQEfAPcHq",
        "outputId": "71f7f94c-2a69-4699-e494-2db498153990",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 66.25%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.76      0.69     12500\n",
            "           1       0.70      0.57      0.63     12500\n",
            "\n",
            "    accuracy                           0.66     25000\n",
            "   macro avg       0.67      0.66      0.66     25000\n",
            "weighted avg       0.67      0.66      0.66     25000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Implement this\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_test_pred = knn.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluating performance on test set\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Detailed classification report\n",
        "print(classification_report(y_test, y_test_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Experimentation\n",
        "\n",
        "For each of the following tasks, track both the **weighted F1-score** and **accuracy**:\n",
        "\n",
        "1. **Change the binary parameter in CountVectorizer**: Test both `binary=True` and `binary=False`, and evaluate performance.\n",
        "2. **Switch to TfidfVectorizer**: Replace the CountVectorizer with TfidfVectorizer and compare results.\n",
        "3. **Adjust the max_features**: Experiment with different values of `max_features` for both TfidfVectorizer and CountVectorizer (`binary=True`).\n",
        "4. **Optimize KNN**: Select the best-performing model from task 3 and vary the number of neighbors (`n_neighbors`) in the KNN classifier.\n"
      ],
      "metadata": {
        "id": "Lhp8mXM_Ax8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Initialize CountVectorizer with binary=False\n",
        "vectorizer_count_false = CountVectorizer(binary=False, max_features=5000)\n",
        "X_train_count_false = vectorizer_count_false.fit_transform(X_train)\n",
        "X_test_count_false = vectorizer_count_false.transform(X_test)\n",
        "\n",
        "# Initialize CountVectorizer with binary=True\n",
        "vectorizer_count_true = CountVectorizer(binary=True, max_features=5000)\n",
        "X_train_count_true = vectorizer_count_true.fit_transform(X_train)\n",
        "X_test_count_true = vectorizer_count_true.transform(X_test)\n",
        "\n",
        "# Function to train and evaluate KNN\n",
        "def evaluate_knn(X_train, y_train, X_test, y_test, n_neighbors=5):\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    return accuracy, f1\n",
        "\n",
        "# Evaluate KNN with binary=False\n",
        "accuracy_count_false, f1_count_false = evaluate_knn(X_train_count_false, y_train, X_test_count_false, y_test)\n",
        "print(f\"CountVectorizer (binary=False): Accuracy = {accuracy_count_false*100:.2f}%, F1-score = {f1_count_false:.2f}\")\n",
        "\n",
        "# Evaluate KNN with binary=True\n",
        "accuracy_count_true, f1_count_true = evaluate_knn(X_train_count_true, y_train, X_test_count_true, y_test)\n",
        "print(f\"CountVectorizer (binary=True): Accuracy = {accuracy_count_true*100:.2f}%, F1-score = {f1_count_true:.2f}\")\n",
        "\n",
        "\n",
        "# Implement this"
      ],
      "metadata": {
        "id": "9RpHvtEWCVB1",
        "outputId": "bc910605-34e5-4978-c98d-499390afa208",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorizer (binary=False): Accuracy = 62.11%, F1-score = 0.62\n",
            "CountVectorizer (binary=True): Accuracy = 62.74%, F1-score = 0.63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2\n",
        "\n",
        "# Initialize TfidfVectorizer\n",
        "vectorizer_tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer_tfidf.transform(X_test)\n",
        "\n",
        "# Evaluate KNN with TfidfVectorizer\n",
        "accuracy_tfidf, f1_tfidf = evaluate_knn(X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
        "print(f\"TfidfVectorizer: Accuracy = {accuracy_tfidf*100:.2f}%, F1-score = {f1_tfidf:.2f}\")\n",
        "\n",
        "# Implement this"
      ],
      "metadata": {
        "id": "6bNcCQ2PCfiu",
        "outputId": "ca9a8e21-592e-4f9b-b478-41485fd0585e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TfidfVectorizer: Accuracy = 66.48%, F1-score = 0.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3\n",
        "\n",
        "# Function to evaluate KNN with varying max_features\n",
        "def experiment_with_max_features(vectorizer, max_features_list, binary=False):\n",
        "    for max_features in max_features_list:\n",
        "        if isinstance(vectorizer, CountVectorizer):\n",
        "            vectorizer = CountVectorizer(binary=binary, max_features=max_features)\n",
        "        else:\n",
        "            vectorizer = TfidfVectorizer(max_features=max_features)\n",
        "\n",
        "        # Transform the data\n",
        "        X_train_vect = vectorizer.fit_transform(X_train)\n",
        "        X_test_vect = vectorizer.transform(X_test)\n",
        "\n",
        "        # Evaluate KNN\n",
        "        accuracy, f1 = evaluate_knn(X_train_vect, y_train, X_test_vect, y_test)\n",
        "        print(f\"max_features={max_features}: Accuracy = {accuracy*100:.2f}%, F1-score = {f1:.2f}\")\n",
        "\n",
        "# List of max_features to test\n",
        "max_features_list = [1000, 2000, 5000, 10000]\n",
        "\n",
        "print(\"\\nCountVectorizer (binary=True) with different max_features:\")\n",
        "experiment_with_max_features(CountVectorizer(binary=True), max_features_list)\n",
        "\n",
        "print(\"\\nTfidfVectorizer with different max_features:\")\n",
        "experiment_with_max_features(TfidfVectorizer(), max_features_list)\n",
        "\n",
        "\n",
        "# Implement this"
      ],
      "metadata": {
        "id": "M_bnccPMCgM9",
        "outputId": "b4049ba0-e582-4e7c-bb43-bd547eb7374d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CountVectorizer (binary=True) with different max_features:\n",
            "max_features=1000: Accuracy = 62.03%, F1-score = 0.62\n",
            "max_features=2000: Accuracy = 62.20%, F1-score = 0.62\n",
            "max_features=5000: Accuracy = 62.11%, F1-score = 0.62\n",
            "max_features=10000: Accuracy = 61.91%, F1-score = 0.62\n",
            "\n",
            "TfidfVectorizer with different max_features:\n",
            "max_features=1000: Accuracy = 62.03%, F1-score = 0.62\n",
            "max_features=2000: Accuracy = 62.20%, F1-score = 0.62\n",
            "max_features=5000: Accuracy = 62.11%, F1-score = 0.62\n",
            "max_features=10000: Accuracy = 61.91%, F1-score = 0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 4\n",
        "\n",
        "# Function to experiment with different n_neighbors\n",
        "def experiment_with_knn_neighbors(X_train, X_test, y_train, y_test, neighbors_list):\n",
        "    for n_neighbors in neighbors_list:\n",
        "        accuracy, f1 = evaluate_knn(X_train, y_train, X_test, y_test, n_neighbors=n_neighbors)\n",
        "        print(f\"n_neighbors={n_neighbors}: Accuracy = {accuracy*100:.2f}%, F1-score = {f1:.2f}\")\n",
        "\n",
        "# List of n_neighbors to test\n",
        "neighbors_list = [3, 5, 7, 9]\n",
        "\n",
        "print(\"\\nOptimizing KNN with TfidfVectorizer (best model):\")\n",
        "experiment_with_knn_neighbors(X_train_tfidf, X_test_tfidf, y_train, y_test, neighbors_list)\n",
        "\n",
        "\n",
        "# Implement this"
      ],
      "metadata": {
        "id": "OL1koC0RChNf",
        "outputId": "05c7d36c-ddce-4ac3-b16a-71b64b6475d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimizing KNN with TfidfVectorizer (best model):\n",
            "n_neighbors=3: Accuracy = 64.85%, F1-score = 0.65\n",
            "n_neighbors=5: Accuracy = 66.48%, F1-score = 0.66\n",
            "n_neighbors=7: Accuracy = 67.34%, F1-score = 0.67\n",
            "n_neighbors=9: Accuracy = 68.23%, F1-score = 0.68\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_python3",
      "language": "python",
      "name": "conda_python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}